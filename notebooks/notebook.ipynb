{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Instalação da biblioteca para interagir com a API Gemini\n",
    "!pip install google-generativeai\n",
    "\n",
    "# Importação da biblioteca\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import google.generativeai as genai\n",
    "import json\n",
    "from google.colab import userdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "API_KEY = userdata.get('GOOGLE_API_KEY')\n",
    "\n",
    "\n",
    "# Autenticação (substitua pela sua chave de API)\n",
    "genai.configure(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ex 07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Notícia (substitua pelo texto da notícia que você deseja resumir)\n",
    "noticia = \"\"\"\n",
    "Celso Araujo Sampaio de Novais, de 41 anos, foi atingido por um tiro de fuzil nas costas e estava internado na Unidade de Terapia Intensiva (UTI) do Hospital Geral de Guarulhos.\n",
    "\n",
    "A comunicação do óbito foi registrada no 7º DP da cidade, de acordo com a Secretaria de Segurança Pública de São Paulo.\n",
    "\n",
    "Além de Sampaio, outras duas pessoas foram atingidas: um homem, de 39 anos, que também foi internado no Hospital Geral de Guarulhos, e uma mulher, de 28 anos, que recebeu atendimento médico e foi liberada em seguida – ela foi ouvida pelos policiais no local.\n",
    "\n",
    "Foram ao menos 27 disparos efetuados por dois criminosos, segundo informações da perícia do Departamento de Homicídios e Proteção à Pessoa Humana (DHPP) da Polícia Civil, que investiga o caso.\n",
    "\"\"\"\n",
    "\n",
    "# Prompt com exemplos para guiar o resumo\n",
    "prompt = f\"\"\"\n",
    "**Instruções:** Resuma a notícia abaixo em 1 sentença usando suas próprias palavras.\n",
    "\n",
    "**Exemplo 1:**\n",
    "Notícia: \"O governo anunciou hoje um novo plano de saúde para os cidadãos.\"\n",
    "Resumo: \"O governo lançou um novo plano de saúde.\"\n",
    "\n",
    "**Exemplo 2:**\n",
    "Notícia: \"A empresa X anunciou que irá fechar 500 vagas de trabalho.\"\n",
    "Resumo: \"A empresa X irá demitir 500 funcionários.\"\n",
    "\n",
    "**Notícia:**\n",
    "{noticia}\n",
    "\n",
    "**Resumo:**\n",
    "\"\"\"\n",
    "\n",
    "# Executando o prompt com o modelo Gemini\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "response = model.generate_content(prompt)\n",
    "\n",
    "# Exibindo a resposta gerada\n",
    "print(\"Resumo gerado pelo LLM:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ex 08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Notícias escolhidas\n",
    "noticia = \"\"\"\n",
    "    Notícia 1: O presidente da República, Luiz Inácio Lula da Silva, anunciou ontem que o governo vai investir R$ 1 bilhão em infraestrutura para o estado de São Paulo.\n",
    "    Notícia 2: A empresa de tecnologia, Google, anunciou que vai criar 1.000 novos empregos no Brasil nos próximos dois anos.\n",
    "    Notícia 3: O ministro da Educação, Abraham Bragança, disse que o governo vai aumentar o investimento em educação em 10% no próximo ano.\n",
    "\"\"\"\n",
    "\n",
    "# Prompt para o LLM\n",
    "prompt = f\"\"\"Identifique as menções a diferentes entidades (pessoas, órgãos públicos, empresas, etc.) na seguinte notícia:\"\n",
    "\n",
    "**Notícia:**\n",
    "{noticia}\n",
    "\"\"\"\n",
    "\n",
    "# Executando o prompt com o modelo Gemini\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "response = model.generate_content(prompt)\n",
    "\n",
    "# Exibindo a resposta gerada\n",
    "print(\"Resumo gerado pelo LLM:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ex 09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "\n",
    "# Prompt para o LLM\n",
    "prompt = f\"\"\"\n",
    "Água mole em pedra dura, tanto bate até que fura.\n",
    "\"\"\"*500\n",
    "\n",
    "print(f\"Quantidade de palavras: {len(prompt.split())}\")\n",
    "\n",
    "# Executando o prompt com o modelo Gemini\n",
    "response = model.generate_content(prompt)\n",
    "\n",
    "# Exibindo a resposta gerada\n",
    "print(\"Resumo gerado pelo LLM:\")\n",
    "print(response.usage_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ex 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Carregar o arquivo YAML\n",
    "with open('roteiro.yml', 'r') as f:\n",
    "    roteiro = yaml.safe_load(f)\n",
    "\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "\n",
    "# Executar os prompts para cada cidade\n",
    "for cidade, prompt in roteiro['roteiro'].items():\n",
    "    print(f\"**{cidade}**\")\n",
    "    resposta = model.generate_content(prompt['prompt'])\n",
    "    print(resposta)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ex 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "roteiro:\n",
    "  atenas:\n",
    "    prompt: \"Liste 3 pontos turísticos de Atenas, o número anual de visitantes e uma breve descrição de cada um. Faça com que a resposta seja um json. Os visitantes anuais são um número sem ponto ou vírgula. Evite o fórum romano. Exemplo: nome:acropole, visitantes_anuais:320000, desc:antigo sitio\"\n",
    "  roma:\n",
    "    prompt: \"Liste 3 pontos turísticos de Roma, o número anual de visitantes e uma breve descrição de cada um. Faça com que a resposta seja um json. Os visitantes anuais são um número sem ponto ou vírgula. Evite o fórum romano. Exemplo: nome:acropole, visitantes_anuais:320000, desc:antigo sitio\"\n",
    " \n",
    "'''\n",
    "\n",
    "\n",
    "with open('roteiro.yml', 'r') as f:\n",
    "    roteiro = yaml.safe_load(f)\n",
    "\n",
    "# Definir a API do Gemini\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "\n",
    "responseList = []\n",
    "for cidade, prompt in roteiro['roteiro'].items():\n",
    "    response = model.generate_content(prompt['prompt'])\n",
    "    entrada = response.text\n",
    "    entrada = entrada.replace(\"```json\", \"\" , 1)\n",
    "    entrada = entrada.replace(\"```\", \"\" , 1)\n",
    "    entrada = entrada.replace(\"\\n\",\"\")\n",
    "    entrada = entrada.replace(\" \",\"\", 4)\n",
    "\n",
    "\n",
    "    responseList.append(entrada)\n",
    "    print(entrada)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dados = []\n",
    "\n",
    "\n",
    "json_data_atenas = json.loads(responseList[0])\n",
    "dados.append(json_data_atenas)\n",
    "\n",
    "json_data_roma = json.loads(responseList[1])\n",
    "dados.append(json_data_roma)\n",
    "\n",
    "print(json_data_atenas)\n",
    "print(json_data_roma)\n",
    "print(dados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame(dados[0])\n",
    "\n",
    "df['cidade'] = 'Atenas'\n",
    "\n",
    "df2 = pd.DataFrame(dados[1])\n",
    "df2['cidade'] = 'Roma'\n",
    "\n",
    "df_final = pd.concat ([df, df2])\n",
    "print(df_final)\n",
    "\n",
    "\n",
    "# Plotar o gráfico de barras horizontais\n",
    "plt.figure(figsize=(12, 6))\n",
    "cores = {'Roma': 'red', 'Atenas': 'blue'}  # Define cores para cada cidade\n",
    "for cidade in df_final['cidade'].unique():\n",
    "  plt.barh(df_final.loc[df_final['cidade'] == cidade, 'nome'], df_final.loc[df_final['cidade'] == cidade, 'visitantes_anuais'],\n",
    "            label=cidade, color=cores.get(cidade, 'gray'))\n",
    "plt.xlabel('Número de Visitantes (em milhões)')\n",
    "plt.ylabel('Pontos Turísticos')\n",
    "plt.title('Número de visitantes por ponto turístico')\n",
    "plt.legend(loc='best')\n",
    "plt.xticks([0, 1000000, 2000000, 3000000, 4000000, 5000000, 6000000, 7000000, 8000000, 9000000, 10000000], ['0', '1M', '2M', '3M', '4M', '5M', '6M', '7M', '8M', '9M', '10M'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
